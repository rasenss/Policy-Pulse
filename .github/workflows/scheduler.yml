name: Auto Fetch Twitter Data

on:
  schedule:
    # Jalankan setiap 6 jam sekali
    - cron: '0 */6 * * *'
  workflow_dispatch: # Agar bisa dijalankan manual lewat tombol di GitHub

jobs:
  laravel-fetch:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Setup PHP
      uses: shivammathur/setup-php@v2
      with:
        php-version: '8.2'
        extensions: mbstring, bcmath, pdo, pdo_pgsql

    - name: Install Dependencies
      run: composer install --no-progress --prefer-dist
      
    - name: Install Node.js & Puppeteer
      run: |
        npm install
        npm install puppeteer puppeteer-extra puppeteer-extra-plugin-stealth

    - name: Run Twitter Scraper
      env:
        # PENTING: MENGGUNAKAN DB_URL UNTUK MENCEGAH PORT CORRUPTION
        # DB_URL akan berisi semua variabel koneksi yang digabung.
        # Format: postgresql://USER:PASS@HOST:PORT/DATABASE
        DB_URL: postgresql://${{ secrets.DB_USERNAME }}:${{ secrets.DB_PASSWORD }}@${{ secrets.DB_HOST }}:${{ secrets.DB_PORT }}/${{ secrets.DB_DATABASE }}
        
        # Variabel Lain (Diperlukan Laravel)
        DB_CONNECTION: pgsql
        APP_KEY: ${{ secrets.APP_KEY }} 
        TWITTER_API_KEY: ${{ secrets.TWITTER_API_KEY }} 
        
      run: |
        # Membuat file .env dummy untuk GitHub Actions
        touch .env
        echo "APP_ENV=testing" >> .env
        echo "APP_KEY=${{ env.APP_KEY }}" >> .env
        echo "DB_CONNECTION=${{ env.DB_CONNECTION }}" >> .env
        # Memasukkan URL koneksi lengkap
        echo "DB_URL=${{ env.DB_URL }}" >> .env
        
        # Jalankan Scraper
        php artisan twitter:fetch